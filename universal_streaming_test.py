#!/usr/bin/env python3
"""
AssemblyAI Universal Streaming Test (v3 API)
Uses the new Universal Streaming API with automatic language detection
Note: Currently optimized for English, Spanish may work with auto-detection
"""

import asyncio
import time
import threading
import sys
import signal
import logging

try:
    import assemblyai as aai
    from assemblyai.streaming.v3 import (
        BeginEvent,
        StreamingClient,
        StreamingClientOptions,
        StreamingError,
        StreamingEvents,
        StreamingParameters,
        TerminationEvent,
        TurnEvent,
    )
except ImportError:
    print("âŒ Error: AssemblyAI v3 streaming not available. Please upgrade: pip install --upgrade assemblyai")
    sys.exit(1)

try:
    import pyaudio
except ImportError:
    print("âŒ Error: PyAudio not installed. Run: pip install pyaudio")
    sys.exit(1)

# Configuration
ASSEMBLY_API_KEY = "50eb210feb72457593d3f811a9f2a698"
SAMPLE_RATE = 16000
CHUNK_SIZE = 1024
CHANNELS = 1
FORMAT = pyaudio.paInt16

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UniversalStreamingTester:
    def __init__(self):
        print("ğŸ¤ AssemblyAI Universal Streaming Test")
        print("=" * 50)
        print("â„¹ï¸  Using Universal Streaming API (v3)")
        print("ğŸŒ Language: Automatic detection (optimized for English, may detect Spanish)")
        print("=" * 50)
        
        self.client = None
        self.audio = None
        self.stream = None
        self.is_running = False
        
        # Metrics
        self.turns_received = 0
        self.words_transcribed = 0
        self.session_start_time = None

    def setup_audio(self):
        """Setup audio input"""
        try:
            self.audio = pyaudio.PyAudio()
            
            # Find first available input device
            input_device = None
            print("\nğŸ” Available audio devices:")
            for i in range(self.audio.get_device_count()):
                info = self.audio.get_device_info_by_index(i)
                if info['maxInputChannels'] > 0:
                    print(f"   {i}: {info['name']} ({info['maxInputChannels']} ch)")
                    if input_device is None:
                        input_device = i
            
            if input_device is None:
                print("âŒ No audio input device found!")
                return False
            
            device_info = self.audio.get_device_info_by_index(input_device)
            print(f"ğŸ¯ Using device: {device_info['name']}")
            
            # Open audio stream
            self.stream = self.audio.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=SAMPLE_RATE,
                input=True,
                input_device_index=input_device,
                frames_per_buffer=CHUNK_SIZE,
            )
            
            print("âœ… Audio stream ready")
            return True
            
        except Exception as e:
            print(f"âŒ Audio setup failed: {e}")
            return False

    def on_begin(self, client, event: BeginEvent):
        """Called when streaming session begins"""
        self.session_start_time = time.time()
        print(f"ğŸ”— Session started: {event.id}")
        print("ğŸ¯ Speak now - transcription will appear below:")
        print("ğŸ’¡ Try speaking in Spanish to test language detection")
        print("-" * 50)

    def on_turn(self, client, event: TurnEvent):
        """Called when turn data is received"""
        if not event.transcript.strip():
            return
            
        self.turns_received += 1
        
        # Count words
        words = event.transcript.split()
        self.words_transcribed += len(words)
        
        # Show transcript with status
        status = "END" if event.end_of_turn else "PARTIAL"
        formatted_status = "FORMATTED" if event.turn_is_formatted else "RAW"
        confidence = f"{event.end_of_turn_confidence:.2f}" if hasattr(event, 'end_of_turn_confidence') else "N/A"
        
        print(f"ğŸ¯ [{status}] {event.transcript}")
        print(f"   ğŸ“Š Turn #{event.turn_order} | {formatted_status} | Confidence: {confidence} | Words: {len(words)}")
        
        # Auto-format if end of turn and not formatted
        if event.end_of_turn and not event.turn_is_formatted:
            print("ğŸ”„ Requesting formatting...")

    def on_terminated(self, client, event: TerminationEvent):
        """Called when session terminates"""
        duration = event.audio_duration_seconds
        print(f"\nğŸ”Œ Session terminated: {duration:.1f} seconds of audio processed")

    def on_error(self, client, error: StreamingError):
        """Called on errors"""
        print(f"âŒ Streaming error: {error}")

    def create_client(self):
        """Create the streaming client"""
        try:
            self.client = StreamingClient(
                StreamingClientOptions(
                    api_key=ASSEMBLY_API_KEY,
                    api_host="streaming.assemblyai.com",
                )
            )
            
            # Register event handlers
            self.client.on(StreamingEvents.Begin, self.on_begin)
            self.client.on(StreamingEvents.Turn, self.on_turn)
            self.client.on(StreamingEvents.Termination, self.on_terminated)
            self.client.on(StreamingEvents.Error, self.on_error)
            
            print("âœ… Streaming client created")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to create client: {e}")
            return False

    def start_streaming(self):
        """Start the streaming session"""
        try:
            print("ğŸ”„ Connecting to Universal Streaming API...")
            
            # Connect with parameters optimized for real-time transcription
            self.client.connect(
                StreamingParameters(
                    sample_rate=SAMPLE_RATE,
                    format_turns=True,  # Enable text formatting
                    # Optimize for responsiveness
                    min_end_of_turn_silence_when_confident=200,  # Reduced from default 160ms
                    max_turn_silence=2000,  # Reduced from default 2400ms  
                    end_of_turn_confidence_threshold=0.6,  # Slightly lower threshold
                )
            )
            
            print("âœ… Connected to Universal Streaming")
            return True
            
        except Exception as e:
            print(f"âŒ Failed to connect: {e}")
            import traceback
            traceback.print_exc()
            return False

    def audio_loop(self):
        """Audio capture and streaming loop"""
        print("ğŸ¤ Starting audio capture...")
        
        try:
            # Create microphone stream using AssemblyAI's helper
            # Use default parameters for MicrophoneStream
            mic_stream = aai.extras.MicrophoneStream(
                sample_rate=SAMPLE_RATE
            )
            
            print("ğŸ”„ Streaming audio...")
            self.client.stream(mic_stream)
            
        except Exception as e:
            print(f"âŒ Audio streaming error: {e}")
            import traceback
            traceback.print_exc()

    def run(self):
        """Main execution"""
        # Setup audio (for device info, but we'll use AssemblyAI's mic stream)
        if not self.setup_audio():
            return False
            
        # Create client
        if not self.create_client():
            return False
            
        # Start streaming
        if not self.start_streaming():
            return False
            
        # Run audio streaming
        try:
            self.audio_loop()
        except KeyboardInterrupt:
            print("\nğŸ›‘ Stopping...")
        finally:
            self.cleanup()
            
        return True

    def cleanup(self):
        """Clean up resources"""
        print("\nğŸ§¹ Cleaning up...")
        
        if self.client:
            try:
                self.client.disconnect(terminate=True)
                print("âœ… Disconnected from streaming service")
            except:
                pass
                
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            
        if self.audio:
            self.audio.terminate()
            
        if self.session_start_time:
            elapsed = time.time() - self.session_start_time
            print(f"\nğŸ“Š Final Stats:")
            print(f"   â±ï¸  Duration: {elapsed:.1f}s")
            print(f"   ğŸ¯ Turns: {self.turns_received}")
            print(f"   ğŸ”¤ Words: {self.words_transcribed}")
            if elapsed > 0:
                print(f"   ğŸ“ˆ Throughput: {self.words_transcribed/elapsed:.1f} words/second")

def signal_handler(signum, frame):
    print("\nğŸ›‘ Interrupted")
    sys.exit(0)

def main():
    signal.signal(signal.SIGINT, signal_handler)
    
    print("ğŸš€ Starting AssemblyAI Universal Streaming Test...")
    
    tester = UniversalStreamingTester()
    success = tester.run()
    
    if not success:
        print("âŒ Test failed")
        return 1
        
    print("ğŸ‘‹ Test completed!")
    return 0

if __name__ == "__main__":
    sys.exit(main())
